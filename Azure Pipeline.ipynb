{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Create a Pipeline"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to Workspace"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\r\n",
        "from azureml.core import Workspace\r\n",
        "\r\n",
        "# Load the workspace from the saved config file\r\n",
        "ws = Workspace.from_config()\r\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Ready to use Azure ML 1.44.0 to work with ml-tabular_synthesis\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1667213904265
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Compute or connect to it"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "\r\n",
        "vm_size=\"STANDARD_DS11_V2\"\r\n",
        "vm_size=\"STANDARD_NC6_PROMO\"\r\n",
        "compute_name = \"cpu-ds11-cluster\"\r\n",
        "compute_name = \"gpu-nc6-promo\"\r\n",
        "\r\n",
        "try:\r\n",
        "    # Check for existing compute target\r\n",
        "    compute_target = ComputeTarget(workspace=ws, name=compute_name)\r\n",
        "    print('Found existing cluster, use it.')\r\n",
        "except ComputeTargetException:\r\n",
        "    # If it doesn't already exist, create it\r\n",
        "    try:\r\n",
        "        compute_config = AmlCompute.provisioning_configuration(vm_size=vm_size, max_nodes=2)\r\n",
        "        compute_target = ComputeTarget.create(ws, compute_name, compute_config)\r\n",
        "        compute_target.wait_for_completion(show_output=True)\r\n",
        "    except Exception as ex:\r\n",
        "        print(ex)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667038835798
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# alternative: select current compute instance"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "from azureml.core.compute import ComputeTarget\r\n",
        "\r\n",
        "compute_name = \"gpu-nc6-promo\"\r\n",
        "try:\r\n",
        "    # Check for existing compute target\r\n",
        "    compute_target = ComputeTarget(workspace=ws, name=compute_name)\r\n",
        "    print('Found existing Target, use it.')\r\n",
        "except ComputeTargetException as e:\r\n",
        "    print(\"Compute not found: \", e)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing Target, use it.\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667213905551
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment and config"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "# Create a folder for the pipeline step files\r\n",
        "experiment_folder = '../../git_repos/Tabular-Data-Synthesis/src'\r\n",
        "os.makedirs(experiment_folder, exist_ok=True)\r\n",
        "\r\n",
        "print(experiment_folder)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "../../git_repos/Tabular-Data-Synthesis/src\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667213905681
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import  Environment\r\n",
        "\r\n",
        "# Create a Python environment for the experiment (from a .yml file)\r\n",
        "env = Environment.from_conda_specification(\"tabsyn\", \"environment.yml\")\r\n",
        "\r\n",
        "# Register the environment \r\n",
        "env.register(workspace=ws)\r\n",
        "registered_env = Environment.get(ws, 'tabsyn')"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667213906788
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.runconfig import RunConfiguration\r\n",
        "pipeline_run_config = RunConfiguration()\r\n",
        "\r\n",
        "# Use the compute you created above. \r\n",
        "pipeline_run_config.target = compute_target\r\n",
        "\r\n",
        "# Assign the environment to the run configuration\r\n",
        "pipeline_run_config.environment = registered_env\r\n",
        "\r\n",
        "print (\"Run configuration created.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Run configuration created.\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667213906867
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Pipeline"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "input_args = [  \"--config_path\",\r\n",
        "                \"tabular_synthesis/data/config/adult.json\",\r\n",
        "                \"--learn_sigma\",\r\n",
        "                \"True\",\r\n",
        "                \"--iterations\",\r\n",
        "                \"5000\",\r\n",
        "                \"--anneal_lr\",\r\n",
        "                \"True\",\r\n",
        "                \"--batch_size\",\r\n",
        "                \"64\",\r\n",
        "                \"--lr\",\r\n",
        "                \"3e-4\",\r\n",
        "                \"--save_interval\",\r\n",
        "                \"10000\",\r\n",
        "                \"--weight_decay\",\r\n",
        "                \"0.05\",\r\n",
        "                \"--classifier_attention_resolutions\",\r\n",
        "                \"32,16,8\",\r\n",
        "                \"--classifier_depth\",\r\n",
        "                \"2\",\r\n",
        "                \"--classifier_width\",\r\n",
        "                \"64\",\r\n",
        "                \"--classifier_pool\",\r\n",
        "                \"attention\",\r\n",
        "                \"--classifier_resblock_updown\",\r\n",
        "                \"True\",\r\n",
        "                \"--classifier_use_scale_shift_norm\",\r\n",
        "                \"True\",\r\n",
        "                \"--log_interval\",\r\n",
        "                \"25\",\r\n",
        "                \"--eval_interval\",\r\n",
        "                \"50\"\r\n",
        "            ]"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_args = [  \"--config_path\",\r\n",
        "                \"tabular_synthesis/data/config/adult.json\",\r\n",
        "                \"--learn_sigma\",\r\n",
        "                \"True\",\r\n",
        "                \"--iterations\",\r\n",
        "                \"5000\",\r\n",
        "                \"--anneal_lr\",\r\n",
        "                \"True\",\r\n",
        "                \"--batch_size\",\r\n",
        "                \"64\",\r\n",
        "                \"--lr\",\r\n",
        "                \"2e-3\",\r\n",
        "                \"--save_interval\",\r\n",
        "                \"10000\",\r\n",
        "                \"--weight_decay\",\r\n",
        "                \"0.01\",\r\n",
        "                \"--classifier_attention_resolutions\",\r\n",
        "                \"32,16,8\",\r\n",
        "                \"--classifier_depth\",\r\n",
        "                \"4\",\r\n",
        "                \"--classifier_width\",\r\n",
        "                \"64\",\r\n",
        "                \"--classifier_pool\",\r\n",
        "                \"attention\",\r\n",
        "                \"--classifier_resblock_updown\",\r\n",
        "                \"True\",\r\n",
        "                \"--classifier_use_scale_shift_norm\",\r\n",
        "                \"True\",\r\n",
        "                \"--log_interval\",\r\n",
        "                \"10\",\r\n",
        "                \"--eval_interval\",\r\n",
        "                \"25\",\r\n",
        "                \"--noised\",\r\n",
        "                \"True\",\r\n",
        "                \"--classifier_use_fp16\",\r\n",
        "                \"True\"\r\n",
        "            ]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666600135901
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Pipeline for classifier train"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data import OutputFileDatasetConfig\r\n",
        "from azureml.pipeline.steps import PythonScriptStep\r\n",
        "import tempfile\r\n",
        "import os\r\n",
        "\r\n",
        "# Get the training dataset\r\n",
        "adult_ds = ws.datasets.get(\"adult_train\")\r\n",
        "\r\n",
        "\r\n",
        "# Create an OutputFileDatasetConfig (temporary Data Reference) for data passed from step 1 to step 2\r\n",
        "output = OutputFileDatasetConfig(\"output\")\r\n",
        "\r\n",
        "# Step 1, Run the data prep script\r\n",
        "classifier_train = PythonScriptStep(name = \"classifier_train\",\r\n",
        "                                source_directory = experiment_folder,\r\n",
        "                                script_name = \"tabular_synthesis/classifier_train_azure.py\",\r\n",
        "                                arguments = [\"--dataset_path\", adult_ds.as_download(),\r\n",
        "                                             '--output_path', output] + input_args,\r\n",
        "                                compute_target = compute_target,\r\n",
        "                                runconfig = pipeline_run_config,\r\n",
        "                                allow_reuse = True)\r\n",
        "\r\n",
        "print(\"Pipeline steps defined\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666600738310
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\r\n",
        "from azureml.pipeline.core import Pipeline\r\n",
        "from azureml.widgets import RunDetails\r\n",
        "\r\n",
        "# Construct the pipeline\r\n",
        "pipeline_steps = [classifier_train]\r\n",
        "pipeline = Pipeline(workspace=ws, steps=pipeline_steps)\r\n",
        "print(\"Pipeline is built.\")\r\n",
        "\r\n",
        "# Create an experiment and run the pipeline\r\n",
        "experiment = Experiment(workspace=ws, name = 'classifier_train_test0')\r\n",
        "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\r\n",
        "print(\"Pipeline submitted for execution.\")\r\n",
        "RunDetails(pipeline_run).show()\r\n",
        "pipeline_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666543539646
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline for diffusion train"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_args =[\r\n",
        "    \"--learn_sigma\",\r\n",
        "    \"True\",\r\n",
        "    \"--class_cond\",\r\n",
        "    \"True\",\r\n",
        "    \"--num_channels\",\r\n",
        "    \"128\",\r\n",
        "    \"--num_res_blocks\",\r\n",
        "    \"3\",\r\n",
        "    ]\r\n",
        "\r\n",
        "training_args = [\r\n",
        "    \"--iterations\",\r\n",
        "    \"-160\",\r\n",
        "    \"--save_interval\",\r\n",
        "    \"10000\",\r\n",
        "    \"--log_interval\",\r\n",
        "    \"5\",\r\n",
        "    \"--diffusion_steps\",\r\n",
        "    \"2000\",\r\n",
        "    \"--noise_schedule\",\r\n",
        "    \"linear\",\r\n",
        "    \"--lr\",\r\n",
        "    \"1e-4\",\r\n",
        "    \"--weight_decay\",\r\n",
        "    \"0.01\",\r\n",
        "    \"--batch_size\",\r\n",
        "    \"64\",\r\n",
        "    \"--use_fp16\",\r\n",
        "    \"True\",\r\n",
        "    \"--rescale_timesteps\",\r\n",
        "    \"True\"\r\n",
        "]\r\n",
        "\r\n",
        "\r\n",
        "location_args = [  \r\n",
        "    \"--config_path\",\r\n",
        "    \"tabular_synthesis/data/config/adult.json\",\r\n",
        "]\r\n",
        "\r\n",
        "input_args = location_args + model_args + training_args"
      ],
      "outputs": [],
      "execution_count": 42,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667237624201
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data import OutputFileDatasetConfig\r\n",
        "from azureml.pipeline.steps import PythonScriptStep\r\n",
        "import tempfile\r\n",
        "import os\r\n",
        "\r\n",
        "# Get the training dataset\r\n",
        "adult_ds = ws.datasets.get(\"adult_train\")\r\n",
        "\r\n",
        "\r\n",
        "# Create an OutputFileDatasetConfig (temporary Data Reference) for data passed from step 1 to step 2\r\n",
        "output = OutputFileDatasetConfig(\"output\")\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "train_args =  [\"--dataset_path\", adult_ds.as_download(), '--output_path', output] + input_args\r\n",
        "\r\n",
        "# Step 1, Run the data prep script\r\n",
        "image_train = PythonScriptStep(name = \"image_training\",\r\n",
        "                                source_directory = experiment_folder,\r\n",
        "                                script_name = \"tabular_synthesis/image_train_azure.py\",\r\n",
        "                                arguments = train_args,\r\n",
        "                                compute_target = compute_target,\r\n",
        "                                runconfig = pipeline_run_config,\r\n",
        "                                allow_reuse = True)\r\n",
        "\r\n",
        "output2=OutputFileDatasetConfig(\"output2\")\r\n",
        "sample_process_args = [\r\n",
        "                \"--diffusion_steps\",\r\n",
        "                \"500\",\r\n",
        "                \"--noise_schedule\",\r\n",
        "                \"cosine\",\r\n",
        "                \"--num_samples\",\r\n",
        "                \"-1\",\r\n",
        "                \"--batch_size\",\r\n",
        "                \"64\",\r\n",
        "]\r\n",
        "sample_args = [\"--dataset_path\", adult_ds.as_download(), \"--model_path\", output.as_input(), \"--output_path\", output2] + model_args + sample_process_args + location_args\r\n",
        "\r\n",
        "image_sample = PythonScriptStep(name = \"image_sampling\",\r\n",
        "                                source_directory = experiment_folder,\r\n",
        "                                script_name = \"tabular_synthesis/image_sample_azure.py\",\r\n",
        "                                arguments = sample_args,\r\n",
        "                                compute_target = compute_target,\r\n",
        "                                runconfig = pipeline_run_config,\r\n",
        "                                allow_reuse = True)\r\n",
        "\r\n",
        "final_output=OutputFileDatasetConfig(\"final_output\")\r\n",
        "\r\n",
        "eval_args = [\"--real_dataset_path\", adult_ds.as_download(),\"--synthetic_dataset\", output2.as_input(), \"--output_path\", final_output] + location_args\r\n",
        "\r\n",
        "\r\n",
        "quick_eval = PythonScriptStep(name = \"dataset_evaluation\",\r\n",
        "                                source_directory = experiment_folder,\r\n",
        "                                script_name = \"tabular_synthesis/quick_evaluation_azure.py\",\r\n",
        "                                arguments = eval_args,\r\n",
        "                                compute_target = compute_target,\r\n",
        "                                runconfig = pipeline_run_config,\r\n",
        "                                allow_reuse = True)"
      ],
      "outputs": [],
      "execution_count": 43,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667237637906
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\r\n",
        "from azureml.pipeline.core import Pipeline\r\n",
        "from azureml.widgets import RunDetails\r\n",
        "\r\n",
        "# Construct the pipeline\r\n",
        "pipeline_steps = [image_train, image_sample, quick_eval]\r\n",
        "pipeline = Pipeline(workspace=ws, steps=pipeline_steps)\r\n",
        "print(pipeline_steps)\r\n",
        "print(\"Pipeline is built.\")\r\n",
        "\r\n",
        "# Create an experiment and run the pipeline\r\n",
        "experiment = Experiment(workspace=ws, name = 'image_train_sample_eval')\r\n",
        "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\r\n",
        "print(\"Pipeline submitted for execution.\")\r\n",
        "RunDetails(pipeline_run).show()\r\n",
        "pipeline_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[<azureml.pipeline.steps.python_script_step.PythonScriptStep object at 0x7fc233936f40>, <azureml.pipeline.steps.python_script_step.PythonScriptStep object at 0x7fc233936fd0>, <azureml.pipeline.steps.python_script_step.PythonScriptStep object at 0x7fc233953310>]\nPipeline is built.\nCreated step image_training [7d148362][08167c61-47d6-445b-a42c-02c9b373e7f1], (This step will run and generate new outputs)\nCreated step image_sampling [a5fbce43][f25feaee-704b-415d-a3f1-a988c48a52e4], (This step will run and generate new outputs)Created step dataset_evaluation [390cec53][3eb08b4d-67fa-4ca8-93a6-276fb159c099], (This step will run and generate new outputs)\n\nSubmitted PipelineRun cd6cdfd5-35b6-46f8-a7f9-99fd6c0b0d3f\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/cd6cdfd5-35b6-46f8-a7f9-99fd6c0b0d3f?wsid=/subscriptions/49641ae7-6237-4363-b149-e721ac81137a/resourcegroups/rg-tabular_synthesis/workspaces/ml-tabular_synthesis&tid=84c31ca0-ac3b-4eae-ad11-519d80233e6f\nPipeline submitted for execution.\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', â€¦",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f36cfa302c604a33a1caeb13394b5fba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Running\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/cd6cdfd5-35b6-46f8-a7f9-99fd6c0b0d3f?wsid=/subscriptions/49641ae7-6237-4363-b149-e721ac81137a/resourcegroups/rg-tabular_synthesis/workspaces/ml-tabular_synthesis&tid=84c31ca0-ac3b-4eae-ad11-519d80233e6f\", \"run_id\": \"cd6cdfd5-35b6-46f8-a7f9-99fd6c0b0d3f\", \"run_properties\": {\"run_id\": \"cd6cdfd5-35b6-46f8-a7f9-99fd6c0b0d3f\", \"created_utc\": \"2022-10-31T17:34:12.787022Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\", \"azureml.continue_on_step_failure\": \"False\", \"azureml.continue_on_failed_optional_input\": \"True\", \"azureml.pipelineComponent\": \"pipelinerun\"}, \"tags\": {}, \"end_time_utc\": null, \"status\": \"Running\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://mltabularsynth0207693268.blob.core.windows.net/azureml/ExperimentRun/dcid.cd6cdfd5-35b6-46f8-a7f9-99fd6c0b0d3f/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=nUZTC7zihR%2BrvW3bwnF3Vs27PfxwlvNCuDkhyu2tlTQ%3D&skoid=e02c9cbe-04b2-420c-9245-a3f6dafa0c24&sktid=84c31ca0-ac3b-4eae-ad11-519d80233e6f&skt=2022-10-31T10%3A58%3A02Z&ske=2022-11-01T19%3A08%3A02Z&sks=b&skv=2019-07-07&st=2022-10-31T18%3A02%3A08Z&se=2022-11-01T02%3A12%3A08Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://mltabularsynth0207693268.blob.core.windows.net/azureml/ExperimentRun/dcid.cd6cdfd5-35b6-46f8-a7f9-99fd6c0b0d3f/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=F1EhcEyBoD5CfblmPaZBMIoo8uAloc6tzJQDf0VBIQY%3D&skoid=e02c9cbe-04b2-420c-9245-a3f6dafa0c24&sktid=84c31ca0-ac3b-4eae-ad11-519d80233e6f&skt=2022-10-31T10%3A58%3A02Z&ske=2022-11-01T19%3A08%3A02Z&sks=b&skv=2019-07-07&st=2022-10-31T18%3A02%3A08Z&se=2022-11-01T02%3A12%3A08Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://mltabularsynth0207693268.blob.core.windows.net/azureml/ExperimentRun/dcid.cd6cdfd5-35b6-46f8-a7f9-99fd6c0b0d3f/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=ThmgGaBE4YwBEZXi6kwgg%2FtyHspgpP%2BHMCqV0XJyKoA%3D&skoid=e02c9cbe-04b2-420c-9245-a3f6dafa0c24&sktid=84c31ca0-ac3b-4eae-ad11-519d80233e6f&skt=2022-10-31T10%3A58%3A02Z&ske=2022-11-01T19%3A08%3A02Z&sks=b&skv=2019-07-07&st=2022-10-31T18%3A02%3A08Z&se=2022-11-01T02%3A12%3A08Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:42:01\", \"run_number\": \"1667237652\", \"run_queued_details\": {\"status\": \"Running\", \"details\": null}}, \"child_runs\": [{\"run_id\": \"43022ca7-2f2a-4b01-a7e1-997b468a735f\", \"name\": \"image_training\", \"status\": \"Running\", \"start_time\": \"2022-10-31T17:34:28.268204Z\", \"created_time\": \"2022-10-31T17:34:16.439536Z\", \"end_time\": \"\", \"duration\": \"0:42:21\", \"run_number\": 1667237656, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-10-31T17:34:16.439536Z\", \"is_reused\": \"\"}, {\"run_id\": \"\", \"name\": \"image_sampling\", \"status\": \"NotStarted\", \"start_time\": \"\", \"created_time\": \"\", \"end_time\": \"\", \"duration\": \"\"}, {\"run_id\": \"\", \"name\": \"dataset_evaluation\", \"status\": \"NotStarted\", \"start_time\": \"\", \"created_time\": \"\", \"end_time\": \"\", \"duration\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2022-10-31 17:34:14Z] Submitting 1 runs, first five are: 7d148362:43022ca7-2f2a-4b01-a7e1-997b468a735f\\n\", \"graph\": {\"datasource_nodes\": {\"530b8833\": {\"node_id\": \"530b8833\", \"name\": \"adult_train\"}, \"16adfe91\": {\"node_id\": \"16adfe91\", \"name\": \"adult_train\"}, \"e492d36e\": {\"node_id\": \"e492d36e\", \"name\": \"adult_train\"}}, \"module_nodes\": {\"7d148362\": {\"node_id\": \"7d148362\", \"name\": \"image_training\", \"status\": \"Running\", \"_is_reused\": false, \"run_id\": \"43022ca7-2f2a-4b01-a7e1-997b468a735f\"}, \"a5fbce43\": {\"node_id\": \"a5fbce43\", \"name\": \"image_sampling\", \"status\": \"NotStarted\"}, \"390cec53\": {\"node_id\": \"390cec53\", \"name\": \"dataset_evaluation\", \"status\": \"NotStarted\"}}, \"edges\": [{\"source_node_id\": \"530b8833\", \"source_node_name\": \"adult_train\", \"source_name\": \"data\", \"target_name\": \"input__2e14f035\", \"dst_node_id\": \"7d148362\", \"dst_node_name\": \"image_training\"}, {\"source_node_id\": \"16adfe91\", \"source_node_name\": \"adult_train\", \"source_name\": \"data\", \"target_name\": \"input__2e14f035\", \"dst_node_id\": \"a5fbce43\", \"dst_node_name\": \"image_sampling\"}, {\"source_node_id\": \"7d148362\", \"source_node_name\": \"image_training\", \"source_name\": \"output\", \"target_name\": \"input__2e14f035\", \"dst_node_id\": \"a5fbce43\", \"dst_node_name\": \"image_sampling\"}, {\"source_node_id\": \"e492d36e\", \"source_node_name\": \"adult_train\", \"source_name\": \"data\", \"target_name\": \"input__2e14f035\", \"dst_node_id\": \"390cec53\", \"dst_node_name\": \"dataset_evaluation\"}, {\"source_node_id\": \"a5fbce43\", \"source_node_name\": \"image_sampling\", \"source_name\": \"output2\", \"target_name\": \"input__2e14f035\", \"dst_node_id\": \"390cec53\", \"dst_node_name\": \"dataset_evaluation\"}], \"child_runs\": [{\"run_id\": \"43022ca7-2f2a-4b01-a7e1-997b468a735f\", \"name\": \"image_training\", \"status\": \"Running\", \"start_time\": \"2022-10-31T17:34:28.268204Z\", \"created_time\": \"2022-10-31T17:34:16.439536Z\", \"end_time\": \"\", \"duration\": \"0:42:21\", \"run_number\": 1667237656, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-10-31T17:34:16.439536Z\", \"is_reused\": \"\"}, {\"run_id\": \"\", \"name\": \"image_sampling\", \"status\": \"NotStarted\", \"start_time\": \"\", \"created_time\": \"\", \"end_time\": \"\", \"duration\": \"\"}, {\"run_id\": \"\", \"name\": \"dataset_evaluation\", \"status\": \"NotStarted\", \"start_time\": \"\", \"created_time\": \"\", \"end_time\": \"\", \"duration\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.44.0\"}, \"loading\": false}"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "PipelineRunId: cd6cdfd5-35b6-46f8-a7f9-99fd6c0b0d3f\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/cd6cdfd5-35b6-46f8-a7f9-99fd6c0b0d3f?wsid=/subscriptions/49641ae7-6237-4363-b149-e721ac81137a/resourcegroups/rg-tabular_synthesis/workspaces/ml-tabular_synthesis&tid=84c31ca0-ac3b-4eae-ad11-519d80233e6f\nPipelineRun Status: NotStarted\nPipelineRun Status: Running\n\n\nStepRunId: 43022ca7-2f2a-4b01-a7e1-997b468a735f\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/43022ca7-2f2a-4b01-a7e1-997b468a735f?wsid=/subscriptions/49641ae7-6237-4363-b149-e721ac81137a/resourcegroups/rg-tabular_synthesis/workspaces/ml-tabular_synthesis&tid=84c31ca0-ac3b-4eae-ad11-519d80233e6f\nStepRun( image_training ) Status: Queued\nStepRun( image_training ) Status: Running\n\nStepRun(image_training) Execution Summary\n==========================================\nStepRun( image_training ) Status: Finished\n"
        }
      ],
      "execution_count": 44,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667236758699
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch as th\r\n",
        "softmax(th.rand_like(th.Tensor([4,1,2,2])))"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'softmax' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mth\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43msoftmax\u001b[49m(th\u001b[38;5;241m.\u001b[39mrand_like(th\u001b[38;5;241m.\u001b[39mTensor([\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m])))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'softmax' is not defined"
          ]
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667293187832
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "th.rand_like(th.Tensor([4,1,2,2])) * 0.1"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1667042616984
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}